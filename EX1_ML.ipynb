{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e160d3b1",
   "metadata": {},
   "source": [
    "# Machine Learning EX1:\n",
    "# Data:\n",
    "The data consists of features of real estate in different areas of Bangalore.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54fc51a",
   "metadata": {},
   "source": [
    "# Variables:\n",
    "#### availability: is the property available immediately (1) or in the near future (0).\n",
    "#### total_sqft: the area of the property in square feet (1 foot = 30.54 cm).\n",
    "#### bedrooms: the number of bedrooms in the property.\n",
    "#### bath: the number of bathrooms in the property.\n",
    "#### balcony: the number of balconies in the property.\n",
    "#### rank: the ranking of the neighborhood in terms of average price (1 is the highest).\n",
    "#### area_type: is the property type a built up area (B) or plot area (P).\n",
    "#### price in rupees: the price of the property.\n",
    "# Split:\n",
    "#### Train: rows 1-8040. \n",
    "#### Validation: rows 8041-10050.\n",
    "#### Test: rows 10051-12563."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1fbd746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import time\n",
    "from functools import reduce\n",
    "from DecisionTreeClassifier import DecisionTreeClassifier\n",
    "from DecisionTreeRegressor import DecisionTreeRegressor\n",
    "import Ada_Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73154f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, ratio=0.8):\n",
    "    X = X.sample(frac=1).reset_index(drop=True)\n",
    "    return X[:int(len(X) * ratio)], X[int(len(X) * ratio):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc0597d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for grid search\n",
    "def cartesian_product(arr1, arr2):\n",
    "    product = []\n",
    "    for i in arr1:\n",
    "        for j in arr2:\n",
    "            if isinstance(i, tuple):\n",
    "                # (1, 2) and 5 -> (1, 2, 5)\n",
    "                product.append((*i, j))\n",
    "            else:\n",
    "                # 1 and 2 -> (1, 2)\n",
    "                product.append((i, j))\n",
    "    return product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3efe0e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_possible_param_combinations(params):\n",
    "    return reduce(cartesian_product, map(lambda param_name: params[param_name], params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1eb904bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(model, params_to_optimize, X_train, y_train, X_test, y_test):\n",
    "    all_possibilities = all_possible_param_combinations(params_to_optimize)\n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "    for index, possibility in enumerate(all_possibilities):\n",
    "        model_i = model(*possibility)\n",
    "        a = time()\n",
    "        model_i.fit(X_train, y_train)\n",
    "        b = time()\n",
    "        # print('model', index + 1)\n",
    "        # print('trained in', b - a, 'seconds')\n",
    "        accuracy = model_i.score(X_test, y_test)\n",
    "        #         print('accuracy: ', accuracy)\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = model_i\n",
    "        return best_accuracy, best_model\n",
    "\n",
    "    return best_accuracy, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7e4d8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DT_implementation_CLF_setUP(df):\n",
    "    ######################## CLF DECISION TREE ########################\n",
    "    \"\"\"Split the data into clf test & train\"\"\"\n",
    "    df['area_type'] = pd.factorize(df['area_type'])[0]\n",
    "    # Prepare the data data\n",
    "    features = list(df.columns[2:9])\n",
    "    # y - the target classification to determine for each given data\n",
    "    # x - all the features in the tree to help determine the final classification for each data\n",
    "    y_classes = df['area_type']\n",
    "    X_Features = df[features]\n",
    "\n",
    "    # split the data into: train , validation , test sub dataframes\n",
    "\n",
    "    X_train = X_Features.iloc[:8041, :]\n",
    "    X_validation = X_Features.iloc[8041:10051, :]\n",
    "    X_test = X_Features.iloc[10051:12563, :]\n",
    "\n",
    "    y_train = y_classes.iloc[:8041, ]\n",
    "    y_validation = y_classes.iloc[8041:10051, ]\n",
    "    y_test = y_classes.iloc[10051:12563, ]\n",
    "\n",
    "    params_to_optimize = {\n",
    "        'tol': [0.1],\n",
    "        'max_depth': [6],\n",
    "        'min_members': [10, 20, 50],\n",
    "        'criterion': ['gini'],\n",
    "        'split_method': ['binary'],\n",
    "        'max_features': [2, 7]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3638f325",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params_to_optimize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10696/2192862263.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m best_dt_accuracy, best_dt_model = grid_search(DecisionTreeClassifier, params_to_optimize, X_train, y_train, X_test,\n\u001b[0m\u001b[0;32m      2\u001b[0m                                               y_test)\n\u001b[0;32m      3\u001b[0m \u001b[0mbest_dt_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DECISION TREE CLF ACCURACY SCORE: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbest_dt_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'params_to_optimize' is not defined"
     ]
    }
   ],
   "source": [
    "    best_dt_accuracy, best_dt_model = grid_search(DecisionTreeClassifier, params_to_optimize, X_train, y_train, X_test,\n",
    "                                                  y_test)\n",
    "    best_dt_model.fit(X_train, y_train)\n",
    "    print(\"DECISION TREE CLF ACCURACY SCORE: \" + str(+best_dt_accuracy))\n",
    "\n",
    "    \"\"\"TEST SAMPLE optional for visualization\"\"\"\n",
    "    # test_sample = X_train.iloc[33:34, :]\n",
    "    # res_prediction = best_dt_model.predict(test_sample)\n",
    "    # print('\\n depth of the clasification tree: ', best_dt_model.tree_.get_depth())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce9a472b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECISION TREE REG ACCURACY SCORE:  0.4597835644741407\n"
     ]
    }
   ],
   "source": [
    "def DT_implementation_REG_setUP(df):\n",
    "    ######################## REGRESSION DECISION TREE ########################\n",
    "\n",
    "    params_to_optimize = {\n",
    "        'n_learners': [50, 100, 150, 200],\n",
    "        'n_iters_stop': [5],\n",
    "        'loss_tol': [10e-4],\n",
    "        'alpha': [0.1, 0.3, 0.5, 0.8],\n",
    "        'tol': [0.1],\n",
    "        'max_depth': [3],\n",
    "        'min_members': [10, 20],\n",
    "        'split_method': ['binary'],\n",
    "        'max_features': [7],\n",
    "    }\n",
    "\n",
    "    reg_features = list(df.columns[1:8])\n",
    "    X_reg = df[reg_features]\n",
    "    y_reg = df['price in rupees']\n",
    "\n",
    "    X_train = X_reg.iloc[:8041, :]\n",
    "    X_validation = X_reg.iloc[8041:10051, :]\n",
    "    X_test = X_reg.iloc[10051:12563, :]\n",
    "\n",
    "    # y_@ - split the classes data by rows that were requested, from the y_classes column only!\n",
    "    y_train = y_reg.iloc[:8041, ]\n",
    "    y_validation = y_reg.iloc[8041:10051, ]\n",
    "    y_test = y_reg.iloc[10051:12563, ]\n",
    "\n",
    "    reg_tree = DecisionTreeRegressor()\n",
    "    reg_tree.fit(X_train, y_train)\n",
    "    print('DECISION TREE REG ACCURACY SCORE: ', reg_tree.score(X_test, y_test))\n",
    "\n",
    "\n",
    "DT_implementation_CLF_setUP(df=pd.read_csv('data.csv'))\n",
    "DT_implementation_REG_setUP(df=pd.read_csv('data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287a807a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c89ff2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
